{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Show that the firing-rate distribution that maximizes the entropy when the firing rate is constrained to lie in the range $0 \\le r \\le r_\\text{max}$ is given by\n",
    "\n",
    "$$p[r]=\\frac{1}{r_\\text{max}}$$\n",
    "\n",
    "and that its entropy for a fixed resolution $\\Delta r$ is given by\n",
    "\n",
    "$$H=\\log_2r_\\text{max}-\\log_2\\Delta r=\\log_2\\left(\\frac{r_\\text{max}}{\\Delta r}\\right)$$\n",
    "\n",
    "Use a Lagrange multiplier (see the Mathematical Appendix) to constrain the integral of $p[r]$ to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Show that the firing-rate distribution that maximizes the entropy when the mean of the firing rate is held fixed is an exponential, and compute its entropy for a fixed resolution $\\Delta r$. Assume that the firing rate can fall anywhere in the range from 0 to $\\infty$. Use Lagrange multipliers (see the Mathematical Appendix) to constrain the integral of $p[r]$ to 1 and the integral of $p[r]r$ to the fixed average firing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Show that the distribution that maximizes the entropy when the mean and variance of the firing rate are held fixed is a Gaussian, and compute its entropy for a fixed resolution $\\Delta r$. To simplify the mathematics, allow the firing rate to take any value between $-\\infty$ and $+\\infty$. Use Lagrange multipliers (see the Mathematical Appendix) to constrain the integral of $p[r]$ to 1, the integral of $p[r]r$ to the fixed average firing rate $\\langle r\\rangle$, and the integral of $p[r](r - \\langle r\\rangle)^2$ to the fixed variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Using Fourier transforms and\n",
    "\n",
    "$$Q_{LL}(\\vec{a},\\vec{b})=\\langle L_s(\\vec{a})L_s(\\vec{b})\\rangle=\\int d\\vec{x}d\\vec{y}D_s(\\vec{x}-\\vec{a})D_s(\\vec{y}-\\vec{b})\\langle s_s(\\vec{x})s_s(\\vec{y})\\rangle$$\n",
    "\n",
    "solve\n",
    "\n",
    "$$Q_{LL}(\\vec{a},\\vec{b})=\\sigma_L^2\\delta(\\vec{a}-\\vec{b})$$\n",
    "\n",
    "to obtain\n",
    "\n",
    "$$|\\tilde{D}_s\\left(\\vec{\\kappa}\\right)|=\\frac{\\sigma_L}{\\sqrt{\\tilde{Q}_{ss}\\left(\\vec{\\kappa}\\right)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Suppose the filter $L_s\\left(\\vec{a}\\right)$ has a correlation function that satisfies\n",
    "\n",
    "$$Q_{LL}(\\vec{a},\\vec{b})=\\sigma_L^2\\delta(\\vec{a}-\\vec{b})$$\n",
    "\n",
    "Consider a new filter constructed in terms of this old one by writing\n",
    "\n",
    "$$L_s'(\\vec a)=\\int d\\vec{c} U(\\vec{a},\\vec{c})L_s(\\vec{c})$$\n",
    "\n",
    "Show that if $U(\\vec{a},\\vec{c})$ satisfies the condition of an orthogonal transformation,\n",
    "\n",
    "$$\\int d\\vec{c}U(\\vec{a},\\vec{c})U(\\vec{b},\\vec{c})=\\delta(\\vec{a}-\\vec{b})$$\n",
    "\n",
    "the correlation function for this new filter also satisfies that equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "Consider a stimulus $s_r = s_s + \\eta$ that is given by the sum of a true stimulus $s_s$ and a noise term $\\eta$. Values of the true stimulus $s_s$ are drawn from a Gaussian distribution with mean 0 and variance $Q_{ss}$. Values of the noise term $\\eta$ are also obtained from a Gaussian distribution, with mean 0 and variance $Q_{\\eta\\eta}$. The two terms $\\eta$ and $s_s$ are independent of each other. Using the formula for the continuous entropy of a Gaussian random variable calculated in problem 3, calculate the mutual information between $s_r$ and $s_s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "Consider a multivariate signal $s_s$ drawn from a Gaussian distribution with mean 0 and covariance matrix $Q_{ss}$. Compute the continuous entropy of $\\textbf{s}$ in terms of the eigenvalues of $Q_{ss}$, up to the usual resolution term for a continuous entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "\n",
    "Suppose that a stimulus at one point on the retina, and at a given time, $s_r = s_s + \\eta$, is the sum of a true stimulus $s_s$ and a noise term $\\eta$, as in problem 6. Model the retinal processing at this particular location as producing a signal at the thalamus\n",
    "\n",
    "$$s_l = D_s s_r + \\eta_l$$\n",
    "\n",
    "where $D_s$ is a parameter called the transfer constant, and $\\eta_l$ represents an additional, independent source of noise that can be modeled as being drawn from a Gaussian distribution with mean 0 and variance $Q_{\\eta_l\\eta_l}$. Calculate the mutual information $I_l$ between $s_l$ and $s_s$ as a function of $D_s$. The power of the signal produced by the retina is defined as $P_r = \\left\\langle\\left(D_s s_r\\right)^2\\right\\rangle$. By maximizing\n",
    "\n",
    "$$I_l - kP_r$$\n",
    "\n",
    "as a function of $D_s$, find the transfer constant that maximizes the mutual information for a given value of k (with k > 0), a parameter that controls the trade-off between information and power. What happens when $Q_{ss}$, describing the visual signal, gets much smaller than $Q_{\\eta\\eta}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9\n",
    "\n",
    "Consider two independent inputs $s$ and $s'$ drawn from Gaussian distributions with means 0 and with different variances $Q_{ss}$ and $Q_{s's'}$. These generate two thalamic signals, as in exercise 8.\n",
    "\n",
    "$$s_l = D_s s + \\eta \\text{ and } s_l' = D_{s'}s' + \\eta'$$\n",
    "\n",
    "defined by two separate transfer constants, $D_s$ and $D_{s'}$, and two independent noise terms with variances $Q_{\\eta\\eta}$ and $Q_{\\eta'\\eta'}$. Find the transfer constants that maximize the total mutual information $I_l + I_l'$ for a fixed total power $P_r + P_r'$, where the non-primes and primes denote the information and power for $s_l$ and $s_l'$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
